{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkp74/Smart_Transportation_System/blob/main/ML_mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxhXtgGzGSF",
        "outputId": "952dda4e-500c-48ae-d6ba-fc8d4c26604b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpxpy\n",
            "  Downloading gpxpy-1.5.0.tar.gz (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.6/111.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gpxpy\n",
            "  Building wheel for gpxpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpxpy: filename=gpxpy-1.5.0-py3-none-any.whl size=42898 sha256=a5a739cfa4e34572b66d8d3f7828c1855d74539ef77fd67a51cba995b0eeb601\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/9b/8d/b4812540cd01add3ca698dc5903c53b99d15ffbd61f23fdf0a\n",
            "Successfully built gpxpy\n",
            "Installing collected packages: gpxpy\n",
            "Successfully installed gpxpy-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "import gpxpy.geo # Get the haversine distance\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import tree\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "bgQIH3C7zIQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=['tpep_pickup_datetime',\n",
        "           'tpep_dropoff_datetime',\n",
        "           'trip_distance',\n",
        "           'pickup_longitude',\n",
        "           'pickup_latitude',\n",
        "           'dropoff_longitude',\n",
        "           'dropoff_latitude',\n",
        "           'total_amount']"
      ],
      "metadata": {
        "id": "NWADjXSnzPe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting Google Drive with Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOolVGizZz0",
        "outputId": "9bda8742-dd33-40c6-af49-0d2c086dc782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Smart_Transportation_System/taxi_demand_prediction/yellow_tripdata_2015-01.csv\")"
      ],
      "metadata": {
        "id": "AqmXvLmyzjYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data_len = data.shape[0]\n",
        "original_data_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvI9OojM0YBF",
        "outputId": "a91214ba-2d0c-4f13-8a91-bd0b505e034f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12748986"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df, test=False, predict=False):\n",
        "    df = df.dropna(how='any', axis='rows')\n",
        "    df = df[(df.dropoff_latitude != 0) | (df.dropoff_longitude != 0)]\n",
        "    df = df[(df.pickup_latitude != 0) | (df.pickup_longitude != 0)]\n",
        "    \n",
        "    if \"total_amount\" in list(df):\n",
        "        df = df[df.total_amount.between(5, 45)]\n",
        "    \n",
        "    return df\n",
        "\n",
        "data_cleaned = clean_data(data)"
      ],
      "metadata": {
        "id": "omb29aG_01DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "SR-1hCA41JvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to decide where to start removing outliers\n",
        "def remove_outliers(data, start=0, end=100):\n",
        "    data=np.sort(data)\n",
        "    for i in np.linspace(start, end, 10):\n",
        "        i=round(i, 6)\n",
        "        print(str(i).zfill(5) + \" percentile value is \" + str(round(data[int(len(data)*(float(i)/100))-1], 1)))\n",
        "    print(str(float(end)).zfill(3) + \" percentile value is \" + str(data[-1]))"
      ],
      "metadata": {
        "id": "naxKNl_v1EoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_coordinates(df):\n",
        "    nrows = df.shape[0]\n",
        "    df.drop(df.index[\n",
        "        \n",
        "            ~((df['pickup_latitude'].between(40.496115395170364, 40.91553277700258)) &\n",
        "              (df['pickup_longitude'].between(-74.25559136315209, -73.7000090639354))) \n",
        "        \n",
        "    ], inplace=True)\n",
        "    print(\"Number of rows removed due to wrong coordinates is {}\".format(nrows - df.shape[0]))\n",
        "    \n",
        "clean_coordinates(data_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj0xyPFu1TR-",
        "outputId": "df0139d2-cba3-4f0f-86a4-aa461de672cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows removed due to wrong coordinates is 825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 trip duration\n",
        "def clean_trip_duration(df):\n",
        "    # convert from object to datetime\n",
        "    df['tpep_pickup_datetime']  = pd.to_datetime(df['tpep_pickup_datetime'])\n",
        "    df['tpep_dropoff_datetime']  = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "    \n",
        "    # copute the time diffrance between pickup & dropoff\n",
        "    # to covert from nanosecondes to minutes we devide by 1000000000 then by 60\n",
        "    # store trip_duratin column\n",
        "    trip_duration = np.array(df['tpep_dropoff_datetime']-df['tpep_pickup_datetime'])\n",
        "    trip_duration = trip_duration/1000000000/60\n",
        "    df['trip_duration'] = trip_duration.astype(float)\n",
        "    \n",
        "    # drop all records that have trip_duration > 2 hours\n",
        "    #                            trip_duration <= 0\n",
        "    #                            trip_distance <= 0\n",
        "    nrows = df.shape[0]\n",
        "    df.drop(df[(df['trip_duration'] > 160) | \n",
        "               (df['trip_duration'] <= 0)].index, inplace = True)\n",
        "    print(\"Number of rows removed due to wrong trip_duration {}\".format(nrows - df.shape[0]))\n",
        "    \n",
        "    \n",
        "clean_trip_duration(data_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIU33f0N1cmM",
        "outputId": "089f926d-d433-41a2-d26f-6255f7cf0e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows removed due to wrong trip_duration 20229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 pickup_time\n",
        "def clean_pickuptime(df):\n",
        "    return df.rename(columns={'tpep_pickup_datetime': 'pickup_time'})\n",
        "\n",
        "data_cleaned = clean_pickuptime(data_cleaned)"
      ],
      "metadata": {
        "id": "3uQPl8DM13NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 trip_distance\n",
        "def clean_trip_distance(df):\n",
        "    nrows = df.shape[0]\n",
        "    df.drop(df[(df['trip_distance'] <= 0) | (df['trip_distance'] > 77.5)].index, inplace = True)\n",
        "    print(\"Number of rows removed due to speed outliers {}\".format(nrows - df.shape[0]))\n",
        "    \n",
        "clean_trip_distance(data_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bB6k6PW2NDk",
        "outputId": "ca079b73-76b6-4583-e0c9-a5d145dfebe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows removed due to speed outliers 6089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_speed(df):\n",
        "    # computing Taxi speed average (mile/hour)\n",
        "    df['speed'] = df['trip_distance']/df['trip_duration']*60\n",
        "    \n",
        "def clean_speed(df):\n",
        "\n",
        "    # Removing speed anomaly/outliers\n",
        "    nrows = df.shape[0]\n",
        "    df.drop(df[((df['speed'] <= 0) | (df['speed'] > 63.0))].index, inplace = True)\n",
        "    print(\"Number of rows removed due to speed outliers {}\".format(nrows - df.shape[0]))\n",
        "\n",
        "\n",
        "compute_speed(data_cleaned)\n",
        "\n",
        "clean_speed(data_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYwGLVEk2Vr1",
        "outputId": "14fed00d-a09f-4966-cc49-585a30a2029f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows removed due to speed outliers 340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandarallel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwtJZwd-23ao",
        "outputId": "c88efa6a-6ddd-43a3-f81a-21013dda8555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandarallel\n",
            "  Downloading pandarallel-1.6.4.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill>=0.3.1\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1 in /usr/local/lib/python3.9/dist-packages (from pandarallel) (1.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from pandarallel) (5.9.5)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1->pandarallel) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n",
            "Building wheels for collected packages: pandarallel\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandarallel: filename=pandarallel-1.6.4-py3-none-any.whl size=16677 sha256=3fad0f65411cd8e3fb874949017d15ecbbea26859e629fec59decb3fcb499145\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/01/29/deaa71fe596f8d857e57c4fb388db8861e23e6ed0b03204dcb\n",
            "Successfully built pandarallel\n",
            "Installing collected packages: dill, pandarallel\n",
            "Successfully installed dill-0.3.6 pandarallel-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clustering using K-Means with respect to longitude and latitude\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from pandarallel import pandarallel\n",
        "\n",
        "\n",
        "#Clustering pickups\n",
        "print(\"Getting clusters\")\n",
        "coord = data_cleaned[[\"pickup_latitude\", \"pickup_longitude\"]].values\n",
        "regions = MiniBatchKMeans(n_clusters = 30, batch_size = 10000).fit(coord)\n",
        "\n",
        "print(\"Predicting clusters\")\n",
        "cluster_column = regions.predict(data_cleaned[[\"pickup_latitude\", \"pickup_longitude\"]])\n",
        "data_cleaned[\"pickup_cluster\"] = cluster_column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2LlXTTQ2jqd",
        "outputId": "c2cb429a-2d24-4b2d-f298-2286941317c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting clusters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting clusters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but MiniBatchKMeans was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing mins and sec with 0\n",
        "print(\"Removing Minutes and seconds\")\n",
        "pandarallel.initialize()\n",
        "data_cleaned['pickup_time'] = data_cleaned.pickup_time.parallel_apply(lambda x : pd.to_datetime(x).replace(minute=0, second=0) + timedelta(hours=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMbS0hsH3kMi",
        "outputId": "032e7c06-3ad1-4d68-abba-382585fe7be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing Minutes and seconds\n",
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Group by Cluster and time\")\n",
        "df1 = data_cleaned.groupby(['pickup_time','pickup_cluster']).size().reset_index(name='count')\n",
        "\n",
        "print(\"Converting counts to demand percentage\")\n",
        "\n",
        "df1['count'] = df1['count'].parallel_apply(lambda x :  (x / df1['count'].max()))\n",
        "\n",
        "\n",
        "df1['month'] = pd.DatetimeIndex(df1['pickup_time']).month\n",
        "df1['day'] = pd.DatetimeIndex(df1['pickup_time']).day\n",
        "df1['dayofweek'] = pd.DatetimeIndex(df1['pickup_time']).dayofweek\n",
        "df1['hour'] = pd.DatetimeIndex(df1['pickup_time']).hour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ENnOo5Xshq",
        "outputId": "b5a1a256-74b4-4db6-e630-bca6ccb04361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group by Cluster and time\n",
            "Converting counts to demand percentage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into train and test, X and y"
      ],
      "metadata": {
        "id": "QOwpLdDab_kN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I4vMq1KwdgHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1[['pickup_cluster', 'month', 'day', 'hour', 'dayofweek']]\n",
        "y = df1['count']"
      ],
      "metadata": {
        "id": "3Q3ZGCBUbsGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12GKdx8qcIu0",
        "outputId": "26e0a25d-4253-4a64-cfd3-7d3488b542b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22260\n",
            "22260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(X,y , random_state=42, test_size=0.25,  shuffle=True)"
      ],
      "metadata": {
        "id": "SJfSJ-31cZ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models Training"
      ],
      "metadata": {
        "id": "d2CgWmDpdd12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print('model training 0/3 (creating model)', end='\\r')\n",
        "LReg = LinearRegression()\n",
        "\n",
        "print('model training 1/3 (fitting model)', end='\\r')\n",
        "LReg.fit(X_train, y_train)\n",
        "\n",
        "print('model training 2/3 (training model)', end='\\r')\n",
        "LReg_y_pred = LReg.predict(X_test)\n",
        "\n",
        "print('model training 3/3 done!           ', end='\\r')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq2sKOG3dZPQ",
        "outputId": "cf79026b-402d-4d2d-c8cb-75be73590374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model training 0/3 (creating model)\rmodel training 1/3 (fitting model)\rmodel training 2/3 (training model)\rmodel training 3/3 done!           \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model training 0/3 (creating model)', end='\\r')\n",
        "RFRegr = RandomForestRegressor()\n",
        "\n",
        "print('model training 1/3 (fitting model)', end='\\r')\n",
        "RFRegr.fit(X_train, y_train)\n",
        "\n",
        "print('model training 2/3 (training model)', end='\\r')\n",
        "RFRegr_y_pred = RFRegr.predict(X_test)\n",
        "\n",
        "print('model training 3/3 done!           ', end='\\r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ACqb3-0dsep",
        "outputId": "eb89ae6b-3211-4a57-a1e0-254a3ff1a106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model training 0/3 (creating model)', end='\\r')\n",
        "GBRegr = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
        "\n",
        "print('model training 1/3 (fitting model)', end='\\r')\n",
        "GBRegr.fit(X_train, y_train)\n",
        "\n",
        "print('model training 2/3 (training model)', end='\\r')\n",
        "GBRegr_y_pred = GBRegr.predict(X_test)\n",
        "\n",
        "print('model training 3/3 done!           ', end='\\r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF6Nb7oDd3UX",
        "outputId": "4e5a6c65-a1fc-4ee3-8feb-69a9dcf5a25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluation(algorithem_name, X_Test, y_pred, y_true):\n",
        "    \n",
        "    # R2 and Adjasted R2\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    adj_r2 = 1-(1-r2)*((len(X_Test)-1)/(len(X_Test)-X_Test.shape[1]-1))\n",
        "    # MSE and RMSE\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = math.sqrt(mse)\n",
        "    \n",
        "    # print in table\n",
        "    x = PrettyTable()\n",
        "    x.add_row(['R2', r2])\n",
        "    x.add_row(['Adjusted R2', adj_r2])\n",
        "    x.add_row(['MSE',mse])\n",
        "    x.add_row(['RMSE', rmse])\n",
        "    x.title = algorithem_name\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "N1iTk0XbeVBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation('y True',X_Test=X_test, y_pred=y_test, y_true=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkBKaQFNexGb",
        "outputId": "eadc63a0-3b6b-4d68-a471-0069ec5e1c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+\n",
            "|   Field 1   | Field 2 |\n",
            "+-------------+---------+\n",
            "|      R2     |   1.0   |\n",
            "| Adjusted R2 |   1.0   |\n",
            "|     MSE     |   0.0   |\n",
            "|     RMSE    |   0.0   |\n",
            "+-------------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation('Linear Regression',X_Test=X_test, y_pred=LReg_y_pred, y_true=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBTr8poRfAqX",
        "outputId": "84d7586e-83a7-42f6-e5bc-2ccbf31719e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------------+\n",
            "|   Field 1   |       Field 2        |\n",
            "+-------------+----------------------+\n",
            "|      R2     |  0.0950983319699581  |\n",
            "| Adjusted R2 |  0.0942844250909961  |\n",
            "|     MSE     | 0.016586335870444738 |\n",
            "|     RMSE    | 0.12878794924388204  |\n",
            "+-------------+----------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation('Random Forest',X_Test=X_test, y_pred=RFRegr_y_pred, y_true=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GZSTpdVfJuZ",
        "outputId": "aca6f4a9-9fe3-4aa0-edaa-d0b41f2943fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------------+\n",
            "|   Field 1   |        Field 2        |\n",
            "+-------------+-----------------------+\n",
            "|      R2     |   0.9572284350793755  |\n",
            "| Adjusted R2 |   0.9571899645226921  |\n",
            "|     MSE     | 0.0007839785984950337 |\n",
            "|     RMSE    |  0.02799961782766032  |\n",
            "+-------------+-----------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation('Gradient Boosting',X_Test=X_train, y_pred=GBRegr_y_pred, y_true=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbsIaCTsfQAn",
        "outputId": "3fae20c0-6729-4824-c8db-eee40ebe2f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------------+\n",
            "|   Field 1   |       Field 2        |\n",
            "+-------------+----------------------+\n",
            "|      R2     |  0.9727217283871309  |\n",
            "| Adjusted R2 |  0.9727135558568376  |\n",
            "|     MSE     | 0.00049999529332423  |\n",
            "|     RMSE    | 0.022360574530280522 |\n",
            "+-------------+----------------------+\n"
          ]
        }
      ]
    }
  ]
}